{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023, Acadential, All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9-1. MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Torch, Torchvision Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision\n",
    "import numpy as np \n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2-5에서 살펴보았듯이 Torchvision에서는 다양한 데이터셋들을 제공합니다. [torchvision dataset doc](https://pytorch.org/vision/main/datasets.html) \n",
    "1. Cifar10, Cifar100\n",
    "2. MNIST\n",
    "3. Fashion MNIST\n",
    "4. Cityscapes\n",
    "\n",
    "그 중에서 이번 실습에서는 MNIST 데이터셋을 사용해보도록 하겠습니다. [mnist dataset doc](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) \n",
    "\n",
    "MNIST은 0\\~9까지의 수를 분류하는 task에 사용되는 데이터셋입니다. 28x28의 크기를 가진 grayscale 이미지와 0~9까지의 label로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mnist dataset from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../.cache',\n",
    "    train=True,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../.cache',\n",
    "    train=False,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision.datasets.mnist.MNIST은 어떤 클라스인지 살펴보겠습니다. \\\n",
    "(fn + F12 로 inspection 해보기)\n",
    "\n",
    "Inspection해보면 MNIST는 torchvision.datasets.vision을 상속받은 클래스임을 알 수 있습니다. \\\n",
    "그럼 이 클라스는 어떤 클라스를 상속받았는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.vision import VisionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VisionDataset은 결국 torch.utils.data.Dataset을 상속받은 클래스라는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sample 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0]  # train_data의 첫번째 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img  # png image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)  # numpy array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(img.dtype)  # uint8 (0~255 integer)\n",
    "print(img.shape)  # (height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST은 흑백 이미지이기 때문에 height, width로만 구성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max =  255\n",
      "Min =  0\n"
     ]
    }
   ],
   "source": [
    "# unit8 특징에 따라 이미지의 각 픽실값은0에서 255사이의 값을 가짐\n",
    "print(\"Max = \", np.max(img))\n",
    "print(\"Min = \", np.min(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array MNIST dataset을 PyTorch Tensor로 변환 그리고 0~1 사이 값으로 정규화.\n",
    "to_tensor = transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = to_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n",
      "Max =  tensor(1.)\n",
      "Min =  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(type(tensor))\n",
    "print(tensor.shape)\n",
    "print(\"Max = \", torch.max(tensor)) \n",
    "print(\"Min = \", torch.min(tensor))\n",
    "\n",
    "# input shape이 추가된 1x28x28이 됨.\n",
    "# to_tensor를 적용하게되면 float타입으로 변환하게 되고 이 tensor의 값은 0에서 1사이의 값으로 표준화되는 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform이 적용된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instane 값을 만들때 Trasnsform 인자로 명시해서 적용이 가능하다.\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../.cache',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../.cache',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = train_data[0]\n",
    "type(img)  # torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더는 데이터셋을 입력 인자로 받고 미니배치의크기, number of worker, shuffling을 할지 등을 정의함\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,  # dataset\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=False # we don't need to shuffle the test data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size: 한번에 학습할 데이터의 개수 (Mini-batch Stochastic Gradient Descent)\n",
    "- num_workers: 데이터를 불러오고 전처리를 실행해주는 병렬 process의 개수.\n",
    "- shuffle: Shuffle=True로 설정하면 Epoch마다 데이터가 섞입니다. Shuffle=False로 설정하면 Epoch마다 데이터가 섞이지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape =  torch.Size([64, 1, 28, 28])\n",
      "Label shape =  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch, label = next(iter(train_dataloader))\n",
    "print(\"Batch shape = \", batch.shape)  # torch.Size([64=미니배치수, 1=인풋채널개수, 28=높이, 28=넓이])\n",
    "print(\"Label shape = \", label.shape)  # torch.Size([64=미니배치수])\n",
    "# 그래서 미니 배치, 인풋 채널 갯수, 하이트, 위스의 크기로 구성되어 있고\n",
    "# 레이블은 미니 배치의 크기인 64인 벡터로 구성되어 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 141.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tbar = tqdm(train_dataloader)\n",
    "# loop에서 매 iteration 마다 배치와 레이블이 샘플링 되며 이들을 모델 학습에\n",
    "# 사용하게된다. 아래코드는 psudo 코드로써 .\n",
    "\n",
    "\n",
    "for batch, label in tbar:\n",
    "    # 1. input X인 배치가 모델의 입력 인자로 넣어줘서 forward pass되어 prediction 값을 구하게 되고 \n",
    "    # pred = model(batch)\n",
    "    \n",
    "    # 2. prediction 값은 레이블 값과 비교되어 손실함수 값을 구하게되고 \n",
    "    # loss = loss_fn(pred, label)\n",
    "    \n",
    "    # 3. 이렇게 구한 손실함수 값을 backward pass 해서 이 손실함수 값에 대한 경사인, loss gradiant를 계산해준다.\n",
    "    # loss.backward()\n",
    "    \n",
    "    # 4. 이렇게 계산된 loss gradient를 기반으로 우리가 gradient decent를 수행할 수 있게된다.\n",
    "    # optimizer.step()\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
